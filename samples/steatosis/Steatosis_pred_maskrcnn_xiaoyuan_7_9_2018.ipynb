{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/labs/konglab/Steatosis_Seg_DP_xiaoyuan'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import skimage.color\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_DIR: /labs/konglab/xiaoyuan/MyProject_2_2/Mask_RCNN-xiaoyuan/\n",
      "/labs/konglab/xiaoyuan/MyProject_2_2/Mask_RCNN-xiaoyuan/mask_rcnn_coco.h5\n"
     ]
    }
   ],
   "source": [
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "import steatosis2\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset directory\n",
    "DATASET_DIR = \"/labs/konglab/Steatosis_Seg_DP_xiaoyuan/test_data_anywhere\"\n",
    "\n",
    "# Inference Configuration\n",
    "config = steatosis2.SteatosisInferenceConfig()\n",
    "#config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same \n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "DEVICE = \"/gpu:1\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# Only inference mode is supported right now\n",
    "TEST_MODE = \"inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteatosisDataset(utils.Dataset):\n",
    "\n",
    "    def load_steatosis(self, dataset_dir):\n",
    "        \"\"\"Load a subset of the nuclei dataset.\n",
    "\n",
    "        dataset_dir: Root directory of the dataset\n",
    "        subset: Subset to load. Either the name of the sub-directory,\n",
    "                such as stage1_train, stage1_test, ...etc. or, one of:\n",
    "                * train: stage1_train excluding validation images\n",
    "                * val: validation images from VAL_IMAGE_IDS\n",
    "        \"\"\"\n",
    "        # Add classes. We have one class.\n",
    "        # Naming the dataset steatosis, and the class steatosis\n",
    "        self.add_class(\"steatosis\", 1, \"steatosis\")\n",
    "\n",
    "        # Which subset?\n",
    "        # \"val\": use hard-coded list above\n",
    "        # \"train\": use data from stage1_train minus the hard-coded list above\n",
    "        # else: use the data from the specified sub-directory\n",
    "        \n",
    "        #if subset in [\"train\", \"val\"] else subset\n",
    "    \n",
    "            # Get image ids from directory names\n",
    "        #print('dataset_dir: {}\\n'.format(dataset_dir))\n",
    "        #print('walk: {}\\n'.format(next(os.walk(dataset_dir))))\n",
    "        #print (\"**********************\\n\")\n",
    "        image_ids = next(os.walk(dataset_dir))[1]\n",
    "        #image_ids = os.listdir(dataset_dir)\n",
    "            \n",
    "        # Add images\n",
    "        for image_id in image_ids:\n",
    "            self.add_image(\n",
    "                \"steatosis\",\n",
    "                image_id=image_id,\n",
    "                path=dataset_dir)\n",
    "        return image_ids\n",
    "                #path=os.path.join(dataset_dir, image_id, \"image/{}.png\".format(image_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 1\n",
      "Classes: ['BG', 'steatosis']\n"
     ]
    }
   ],
   "source": [
    "# Load validation dataset\n",
    "dataset = SteatosisDataset()\n",
    "image_ids=dataset.load_steatosis(DATASET_DIR)\n",
    "dataset.prepare()\n",
    "\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in inference mode\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\",\n",
    "                              model_dir=LOGS_DIR,\n",
    "                              config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights  /labs/konglab/Steatosis_Seg_DP_xiaoyuan/logs/steatosis20180624T1732/mask_rcnn_steatosis_0049.h5\n"
     ]
    }
   ],
   "source": [
    "# Path to a specific weights file\n",
    "weights_path = \"/labs/konglab/Steatosis_Seg_DP_xiaoyuan/logs/steatosis20180624T1732/mask_rcnn_steatosis_0049.h5\"\n",
    "\n",
    "# Or, load the last model you trained\n",
    "#weights_path = model.find_last()[1]\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_instances(image, boxes, masks, class_ids, class_names,\n",
    "                      scores=None, title=\"\",\n",
    "                      figsize=(16, 16), ax=None,\n",
    "                      show_mask=True, show_bbox=True,\n",
    "                      colors=None, captions=None):\n",
    "    \"\"\"\n",
    "    boxes: [num_instance, (y1, x1, y2, x2, class_id)] in image coordinates.\n",
    "    masks: [height, width, num_instances]\n",
    "    class_ids: [num_instances]\n",
    "    class_names: list of class names of the dataset\n",
    "    scores: (optional) confidence scores for each box\n",
    "    title: (optional) Figure title\n",
    "    show_mask, show_bbox: To show masks and bounding boxes or not\n",
    "    figsize: (optional) the size of the image\n",
    "    colors: (optional) An array or colors to use with each object\n",
    "    captions: (optional) A list of strings to use as captions for each object\n",
    "    \"\"\"\n",
    "    # Number of instances\n",
    "    N = boxes.shape[0]\n",
    "    if not N:\n",
    "        print(\"\\n*** No instances to save *** \\n\")\n",
    "    else:\n",
    "        assert boxes.shape[0] == masks.shape[-1] == class_ids.shape[0]\n",
    "\n",
    "    # If no axis is passed, create one and automatically call show()\n",
    "    auto_show = False\n",
    "    if not ax:\n",
    "        _, ax = plt.subplots(1, figsize=figsize)\n",
    "        auto_show = True\n",
    "\n",
    "    # Generate random colors\n",
    "    colors = colors or random_colors(N)\n",
    "\n",
    "    # Show area outside image boundaries.\n",
    "    height, width = image.shape[:2]\n",
    "    ax.set_ylim(height + 10, -10)\n",
    "    ax.set_xlim(-10, width + 10)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "\n",
    "    masked_image = image.astype(np.uint32).copy()\n",
    "    for i in range(N):\n",
    "        color = colors[i]\n",
    "\n",
    "        # Bounding box\n",
    "        if not np.any(boxes[i]):\n",
    "            # Skip this instance. Has no bbox. Likely lost in image cropping.\n",
    "            continue\n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        if show_bbox:\n",
    "            p = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2,\n",
    "                                alpha=0.7, linestyle=\"dashed\",\n",
    "                                edgecolor=color, facecolor='none')\n",
    "            ax.add_patch(p)\n",
    "\n",
    "        # Label\n",
    "        if not captions:\n",
    "            class_id = class_ids[i]\n",
    "            score = scores[i] if scores is not None else None\n",
    "            label = class_names[class_id]\n",
    "            x = random.randint(x1, (x1 + x2) // 2)\n",
    "            caption = \"{} {:.3f}\".format(label, score) if score else label\n",
    "        else:\n",
    "            caption = captions[i]\n",
    "        ax.text(x1, y1 + 8, caption,\n",
    "                color='w', size=11, backgroundcolor=\"none\")\n",
    "\n",
    "        # Mask\n",
    "        mask = masks[:, :, i]\n",
    "        if show_mask:\n",
    "            masked_image = apply_mask(masked_image, mask, color)\n",
    "\n",
    "        # Mask Polygon\n",
    "        # Pad to ensure proper polygons for masks that touch image edges.\n",
    "        padded_mask = np.zeros(\n",
    "            (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n",
    "        padded_mask[1:-1, 1:-1] = mask\n",
    "        contours = find_contours(padded_mask, 0.5)\n",
    "        for verts in contours:\n",
    "            # Subtract the padding and flip (y, x) to (x, y)\n",
    "            verts = np.fliplr(verts) - 1\n",
    "            p = Polygon(verts, facecolor=\"none\", edgecolor=color)\n",
    "            ax.add_patch(p)\n",
    "    ax.imshow(masked_image.astype(np.uint8))\n",
    "    if auto_show:\n",
    "        plt.savefig(\"pred.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path,image_id):\n",
    "        \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n",
    "        \"\"\"\n",
    "        # Load image\n",
    "        print(\"Here is Image_id,{}\\n\".format(image_id))\n",
    "        print(\"Here is the path information {}\\n\".format(path+image_id+\"/\"+image_id+\".png\"))\n",
    "        image_file = path+image_id+\"/\"+image_id+\".png\" \n",
    "        image = skimage.io.imread(image_file)\n",
    "        # If grayscale. Convert to RGB for consistency.\n",
    "        if image.ndim != 3:\n",
    "            image = skimage.color.gray2rgb(image)\n",
    "        # If has an alpha channel, remove it for consistency\n",
    "        if image.shape[-1] == 4:\n",
    "            image = image[..., :3]\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_image_meta(image_id, original_image_shape, image_shape,\n",
    "                       window, scale, active_class_ids):\n",
    "    \"\"\"Takes attributes of an image and puts them in one 1D array.\n",
    "\n",
    "    image_id: An int ID of the image. Useful for debugging.\n",
    "    original_image_shape: [H, W, C] before resizing or padding.\n",
    "    image_shape: [H, W, C] after resizing and padding\n",
    "    window: (y1, x1, y2, x2) in pixels. The area of the image where the real\n",
    "            image is (excluding the padding)\n",
    "    scale: The scaling factor applied to the original image (float32)\n",
    "    active_class_ids: List of class_ids available in the dataset from which\n",
    "        the image came. Useful if training on images from multiple datasets\n",
    "        where not all classes are present in all datasets.\n",
    "    \"\"\"\n",
    "    meta = np.array(\n",
    "        [image_id] +                  # size=1\n",
    "        list(original_image_shape) +  # size=3\n",
    "        list(image_shape) +           # size=3\n",
    "        list(window) +                # size=4 (y1, x1, y2, x2) in image cooredinates\n",
    "        [scale] +                     # size=1\n",
    "        list(active_class_ids)        # size=num_classes\n",
    "    )\n",
    "    return meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_gt(dataset, config, image_id,ID):\n",
    "    \"\"\"Load and return ground truth data for an image (image, mask, bounding boxes).\n",
    "\n",
    "    augment: (Depricated. Use augmentation instead). If true, apply random\n",
    "        image augmentation. Currently, only horizontal flipping is offered.\n",
    "    augmentation: Optional. An imgaug (https://github.com/aleju/imgaug) augmentation.\n",
    "        For example, passing imgaug.augmenters.Fliplr(0.5) flips images\n",
    "        right/left 50% of the time.\n",
    "    use_mini_mask: If False, returns full-size masks that are the same height\n",
    "        and width as the original image. These can be big, for example\n",
    "        1024x1024x100 (for 100 instances). Mini masks are smaller, typically,\n",
    "        224x224 and are generated by extracting the bounding box of the\n",
    "        object and resizing it to MINI_MASK_SHAPE.\n",
    "\n",
    "    Returns:\n",
    "    image: [height, width, 3]\n",
    "    shape: the original shape of the image before resizing and cropping.\n",
    "    class_ids: [instance_count] Integer class IDs\n",
    "    bbox: [instance_count, (y1, x1, y2, x2)]\n",
    "    mask: [height, width, instance_count]. The height and width are those\n",
    "        of the image unless use_mini_mask is True, in which case they are\n",
    "        defined in MINI_MASK_SHAPE.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load image and mask\n",
    "    print(\"Here is Image_id {}\\n\".format(image_id))\n",
    "    #print(\"Here is the Image_ids {}\\n\".format(image_ids))\n",
    "    print(DATASET_DIR+image_id+\"/\"+image_id+\".png\")\n",
    "   \n",
    "    image = load_image(DATASET_DIR,image_id)\n",
    "    print(\"ok11\")\n",
    " \n",
    "    original_shape = image.shape\n",
    "    print(\"ok1\")\n",
    "    image, window, scale, padding, crop = utils.resize_image(\n",
    "        image,\n",
    "        min_dim=config.IMAGE_MIN_DIM,\n",
    "        min_scale=config.IMAGE_MIN_SCALE,\n",
    "        max_dim=config.IMAGE_MAX_DIM,\n",
    "        mode=config.IMAGE_RESIZE_MODE)\n",
    "    \n",
    "    # Active classes\n",
    "    # Different datasets have different classes, so track the\n",
    "    # classes supported in the dataset of this image.\n",
    "    active_class_ids = np.zeros([dataset.num_classes], dtype=np.int32)\n",
    "    print(\"ok12\")\n",
    "    print(dataset.image_info[ID]['source'])\n",
    "    source_class_ids = dataset.source_class_ids[dataset.image_info[ID][\"source\"]]\n",
    "    active_class_ids[source_class_ids] = 1\n",
    "    print(\"ok3\")\n",
    "\n",
    "\n",
    "    # Image meta data\n",
    "    image_meta = compose_image_meta(image_id, original_shape, image.shape,\n",
    "                                    window, scale, active_class_ids)\n",
    "    print(\"ok4\")\n",
    "\n",
    "    return image, image_meta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is Image_id prediction_results\n",
      "\n",
      "/labs/konglab/Steatosis_Seg_DP_xiaoyuan/test_data_anywhereprediction_results/prediction_results.png\n",
      "Here is Image_id,prediction_results\n",
      "\n",
      "Here is the path information /labs/konglab/Steatosis_Seg_DP_xiaoyuan/test_data_anywhereprediction_results/prediction_results.png\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/labs/konglab/Steatosis_Seg_DP_xiaoyuan/test_data_anywhereprediction_results/prediction_results.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a3e1cb91d32e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mID\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image_gt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_molded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-3ed0140f9351>\u001b[0m in \u001b[0;36mload_image_gt\u001b[0;34m(dataset, config, image_id, ID)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_DIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ok11\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-afd86c4804db>\u001b[0m in \u001b[0;36mload_image\u001b[0;34m(path, image_id)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Here is the path information {}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mimage_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m# If grayscale. Convert to RGB for consistency.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_grey, plugin, flatten, **plugin_args)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                                (plugin, kind))\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/site-packages/skimage/io/_plugins/pil_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, dtype, img_num, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/labs/konglab/Steatosis_Seg_DP_xiaoyuan/test_data_anywhereprediction_results/prediction_results.png'"
     ]
    }
   ],
   "source": [
    "ID = -1\n",
    "for image_id in image_ids:\n",
    "    ID = ID+1\n",
    " \n",
    "    image, image_meta = load_image_gt(dataset, config, image_id,ID)\n",
    "    results = model.detect_molded(np.expand_dims(image, 0), np.expand_dims(image_meta, 0), verbose=0)\n",
    "    \n",
    "    r = results[0]\n",
    "\n",
    "    print(gt_class_id)\n",
    "    if len(gt_class_id)==0:\n",
    "        print(\"I changed\")\n",
    "        gt_class_id = [0]\n",
    "    # Display predictions only\n",
    "    save_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset.class_names, r['scores'], ax=get_ax(1),\n",
    "                            show_bbox=False, show_mask=False,\n",
    "                            title=\"Predictions\")\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = random.choice(dataset.image_ids)\n",
    "print(image_id)\n",
    "image, image_meta = load_image_gt(dataset, config, image_id)\n",
    "info = dataset.image_info[image_id]\n",
    "print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
    "                                       dataset.image_reference(image_id)))\n",
    "print(\"Original image shape: \", parse_image_meta(image_meta[np.newaxis,...])[\"original_image_shape\"][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run object detection\n",
    "results = model.detect_molded(np.expand_dims(image, 0), np.expand_dims(image_meta, 0), verbose=1)\n",
    "\n",
    "# Display results\n",
    "r = results[0]\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute AP over range 0.5 to 0.95 and print it\n",
    "utils.compute_ap_range(gt_bbox, gt_class_id, gt_mask,\n",
    "                       r['rois'], r['class_ids'], r['scores'], r['masks'],\n",
    "                       verbose=1)\n",
    "\n",
    "visualize.display_differences(\n",
    "    image,\n",
    "    gt_bbox, gt_class_id, gt_mask,\n",
    "    r['rois'], r['class_ids'], r['scores'], r['masks'],\n",
    "    dataset.class_names, ax=get_ax(),\n",
    "    show_box=False, show_mask=False,\n",
    "    iou_threshold=0.5, score_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_id in dataset.image_ids:\n",
    "        # Load image and run detection\n",
    "        image = dataset.load_image(image_id)\n",
    "        # Detect objects\n",
    "        r = model.detect([image], verbose=0)[0]\n",
    "        # Encode image to RLE. Returns a string of multiple lines\n",
    "        source_id = dataset.image_info[image_id][\"id\"]\n",
    "        rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n",
    "        submission.append(rle)\n",
    "        # Save image with masks\n",
    "        visualize.display_instances(\n",
    "            image, r['rois'], r['masks'], r['class_ids'],\n",
    "            dataset.class_names, r['scores'],\n",
    "            show_bbox=False, show_mask=False,\n",
    "            title=\"Predictions\")\n",
    "        plt.savefig(\"{}/{}.png\".format(submit_dir, dataset.image_info[image_id][\"id\"]))\n",
    "\n",
    "    # Save to csv file\n",
    "submission = \"ImageId,EncodedPixels\\n\" + \"\\n\".join(submission)\n",
    "file_path = os.path.join(submit_dir, \"submit.csv\")\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(submission)\n",
    "    print(\"Saved to \", submit_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
